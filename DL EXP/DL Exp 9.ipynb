{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1rjH7JEvR9QSKCrhUh3B8OQegsRQtI0MV","timestamp":1761022354690}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xSy9uLsbS9x","executionInfo":{"status":"ok","timestamp":1761022728630,"user_tz":-330,"elapsed":92149,"user":{"displayName":"KARTICKEEYAAN M 231501074","userId":"05176090040882858405"}},"outputId":"679f4467-9d5c-4005-c436-bf3ccf002c62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","\u001b[1m1115394/1115394\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m8714/8714\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6ms/step - loss: 2.1873\n","\n","Generated Text:\n","\n","shall i compare thee to a summer's day?\n","\n","rucisa: i sajusberch fry tream lave\n","to-band to me for thou of so, deark'd:\n","you, compi?\n","a kist call in a am ladie diftt some:\n","briegh rive to may my lofe, my king i doul!\n","the bik by prown that the feer out, gover,\n","vered their promen of my tencle. sheo:\n","it\n","heart: mowless you tell henry, as bore ix\n","ace\n"]}],"source":["# ğŸ§ª Experiment: Character-Level Text Generation using LSTM\n","\n","# Step 1: Load and Preprocess the Dataset\n","import tensorflow as tf\n","import numpy as np\n","\n","text_path = tf.keras.utils.get_file(\n","    'shakespeare.txt',\n","    'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",")\n","\n","text = open(text_path, 'r').read().lower()\n","chars = sorted(set(text))\n","c2i = {c: i for i, c in enumerate(chars)}\n","i2c = {i: c for i, c in enumerate(chars)}\n","\n","# Step 2: Create Input and Output Sequences\n","seq_len = 40\n","X, y = [], []\n","\n","for i in range(len(text) - seq_len):\n","    input_seq = text[i:i + seq_len]\n","    target_char = text[i + seq_len]\n","    X.append([c2i[c] for c in input_seq])\n","    y.append(c2i[target_char])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Step 3: Build the LSTM Model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=len(chars), output_dim=64, input_length=seq_len),\n","    tf.keras.layers.LSTM(128),\n","    tf.keras.layers.Dense(len(chars), activation='softmax')\n","])\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","\n","# Train the model (can increase epochs for better results)\n","model.fit(X, y, batch_size=128, epochs=1)\n","\n","# Step 4: Define the Text Generation Function\n","def generate(seed, length=300):\n","    seq = [c2i[c] for c in seed.lower()]\n","    for _ in range(length):\n","        inp = np.array(seq[-seq_len:]).reshape(1, -1)\n","        pred = model.predict(inp, verbose=0)[0]\n","        next_idx = np.random.choice(len(pred), p=pred)\n","        seq.append(next_idx)\n","    return seed + ''.join(i2c[i] for i in seq[len(seed):])\n","\n","# Step 5: Generate and Display Text\n","print(\"\\nGenerated Text:\\n\")\n","print(generate(\"shall i compare thee to a summer's day?\\n\"))\n","\n","# Conclusion:\n","# The LSTM model generates character-level text with Shakespearean style.\n","# Training for more epochs will improve coherence and fluency.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"kqXtKYISHZH9"},"execution_count":null,"outputs":[]}]}