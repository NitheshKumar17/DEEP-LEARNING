{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJ4QiRNFYtSRRQpym2Wu8C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx3mD2P-EK5a","outputId":"546cc956-b70b-4fbc-e6dd-40e4b3ea5606","executionInfo":{"status":"ok","timestamp":1761382739871,"user_tz":-330,"elapsed":1094242,"user":{"displayName":"LOKAA VENKATARATHINAM 231501085","userId":"04150303514892921010"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m8714/8714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 120ms/step - loss: 2.1554\n","\n","Generated Text:\n","\n","shall i compare thee to a summer's day?\n","but what not this is know, in now's about,\n","thou our love to dear!\n","\n","petrum:\n","more, be mahe preadsen of here\n","blanesty colloin's was wellade, a werdy the make.\n","gedple! this be not so make not mores\n","then worst he oughter\n","eard not apod dobe, mored,--\n","camstil's of you, i shall be smerus spenes\n","ale we when \n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","# Load dataset\n","text_path = tf.keras.utils.get_file('shakespeare.txt',\n","    'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt')\n","text = open(text_path, 'r').read().lower()\n","chars = sorted(set(text))\n","c2i = {c:i for i,c in enumerate(chars)}\n","i2c = {i:c for i,c in enumerate(chars)}\n","\n","# Create sequences\n","seq_len = 40\n","X, y = [], []\n","for i in range(len(text)-seq_len):\n","    X.append([c2i[c] for c in text[i:i+seq_len]])\n","    y.append(c2i[text[i+seq_len]])\n","X, y = np.array(X), np.array(y)\n","\n","# Build LSTM model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(len(chars), 64, input_length=seq_len),\n","    tf.keras.layers.LSTM(128),\n","    tf.keras.layers.Dense(len(chars), activation='softmax')\n","])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","model.fit(X, y, batch_size=128, epochs=1)\n","\n","# Text generation\n","def generate(seed, length=300):\n","    seq = [c2i[c] for c in seed.lower()]\n","    for _ in range(length):\n","        inp = np.array(seq[-seq_len:]).reshape(1,-1)\n","        pred = model.predict(inp, verbose=0)[0]\n","        next_idx = np.random.choice(len(pred), p=pred)\n","        seq.append(next_idx)\n","    return seed + ''.join(i2c[i] for i in seq[len(seed):])\n","\n","# Generate text\n","print(\"\\nGenerated Text:\\n\")\n","print(generate(\"shall i compare thee to a summer's day?\\n\"))"]}]}